{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "from datetime import datetime\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, col, lit\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import year, month, dayofmonth, hour, weekofyear, date_format\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType, DateType\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spark_session():\n",
    "    \"\"\"\n",
    "    spark configuration.\n",
    "    \"\"\"\n",
    "    print(\"Start the application\")\n",
    "    spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:2.8.5\") \\\n",
    "        .getOrCreate()\n",
    "    return spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local paths in S3\n",
    "root_path = \"/home/alison/curso/ED-Udacity/capstone-athena/projeto-udacity/data/\"\n",
    "global_temperatures_path = root_path + \"temperatures/GlobalTemperatures.csv\"\n",
    "global_land_temperatures_by_state_path = root_path + \"temperatures/GlobalLandTemperaturesByState.csv\"\n",
    "global_land_temperatures_by_major_city_path = root_path + \"temperatures/GlobalLandTemperaturesByMajorCity.csv\"\n",
    "global_land_temperatures_by_country_path = root_path + \"temperatures/GlobalLandTemperaturesByCountry.csv\"\n",
    "global_land_temperatures_by_city_path = root_path + \"temperatures/GlobalLandTemperaturesByCity.csv\"\n",
    "us_cities_demographics_path = root_path + \"us_cities_demographics.csv\"\n",
    "airport_codes_csv_path = root_path + \"airport_codes_csv.csv\"\n",
    "country_path = root_path + \"country.csv\"\n",
    "transport_vehicle_path = root_path + \"transport_vehicle.csv\"\n",
    "state_usa_path = root_path + 'state_usa.csv'\n",
    "motivation_path = root_path + 'motivation.csv'\n",
    "immigration_path = root_path + 'immigration_data_sample.csv'\n",
    "port_path = root_path + 'port.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_temp_state(spark):\n",
    "    global_temperatures_by_state_schema = StructType([\\\n",
    "                                                  StructField(\"t_state_dt\", DateType(), False),\n",
    "                                                  StructField('t_state_average_temperature', DoubleType(), False),\n",
    "                                                  StructField('t_state_average_temperature_uncertainty', DoubleType(), False),\n",
    "                                                  StructField('t_state_state', StringType(), False),\n",
    "                                                  StructField('t_state_country', StringType(), False)\n",
    "                                          ]) \n",
    "    \n",
    "    return spark\\\n",
    "    .read\\\n",
    "    .format('com.databricks.spark.csv')\\\n",
    "    .option(\"sep\",\",\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .option(\"encoding\", \"UTF-8\")\\\n",
    "    .schema(global_temperatures_by_state_schema)\\\n",
    "    .load(global_land_temperatures_by_state_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_temp_glob(spark):\n",
    "    global_temperatures_schema = StructType([ \\\n",
    "                                  StructField(\"t_glob_dt\", DateType(), False),           \n",
    "                                  StructField(\"t_glob_land_average_temperature\", DoubleType(), False),\n",
    "                                  StructField(\"t_glob_land_average_temperature_uncertainty\", DoubleType(), False),\n",
    "                                  StructField(\"t_glob_land_max_temperature\", DoubleType(), False), \n",
    "                                  StructField(\"t_glob_land_max_temperature_uncertainty\", DoubleType(), False),\n",
    "                                  StructField(\"t_glob_land_min_temperature\", DoubleType(), False), \n",
    "                                  StructField(\"t_glob_land_min_temperature_uncertainty\", DoubleType(), False),\n",
    "                                  StructField(\"t_glob_land_and_ocean_average_temperature\", DoubleType(), False),\n",
    "                                  StructField(\"t_glob_land_and_ocean_average_temperature_uncertainty\", DoubleType(), False)           \n",
    "                            ])\n",
    "    return spark\\\n",
    "            .read\\\n",
    "            .format('com.databricks.spark.csv')\\\n",
    "            .option('sep',',')\\\n",
    "            .option(\"header\", \"true\")\\\n",
    "            .option(\"encoding\", \"UTF-8\")\\\n",
    "            .schema(global_temperatures_schema)\\\n",
    "            .load(global_temperatures_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_temp_major_city(spark):\n",
    "    global_temp_major_city_schema = StructType([\\\n",
    "                                                StructField(\"t_m_city_dt\", DateType(), False),\n",
    "                                                StructField(\"t_m_city_average_temperature\", DoubleType(), False),\n",
    "                                                StructField(\"t_m_city_average_temperature_uncertainty\", DoubleType(), False),\n",
    "                                                StructField(\"t_m_city_city\", StringType(), False),\n",
    "                                                StructField(\"t_m_city_country\", StringType(), False),\n",
    "                                                StructField(\"t_m_city_latitude\", StringType(), False),\n",
    "                                                StructField(\"t_m_city_longitude\", StringType(), False)\n",
    "                                ])\n",
    "    \n",
    "    return spark\\\n",
    "            .read\\\n",
    "            .format('com.databricks.spark.csv')\\\n",
    "            .option('sep',',')\\\n",
    "            .option('header', 'true')\\\n",
    "            .option(\"encoding\", \"UTF-8\")\\\n",
    "            .schema(global_temp_major_city_schema)\\\n",
    "            .load(global_land_temperatures_by_major_city_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_temp_by_country(spark):\n",
    "    global_land_temp_by_country_schema = StructType([\\\n",
    "                                                      StructField(\"t_country_dt\", DateType(), False),\n",
    "                                                      StructField(\"t_country_average_temperature\", DoubleType(), False),\n",
    "                                                      StructField(\"t_country_average_temperature_uncertainty\", DoubleType(), False),\n",
    "                                                      StructField(\"t_country_country\", StringType(), False)\n",
    "                                      ])\n",
    "    return spark\\\n",
    "            .read\\\n",
    "            .format('com.databricks.spark.csv')\\\n",
    "            .option('sep',',')\\\n",
    "            .option('header', 'true')\\\n",
    "            .option(\"encoding\", \"UTF-8\")\\\n",
    "            .schema(global_land_temp_by_country_schema)\\\n",
    "            .load(global_land_temperatures_by_country_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_temp_by_city(spark):\n",
    "    global_land_temp_by_city_schema = StructType([\\\n",
    "                                                  StructField(\"t_city_dt\", DateType(), False),\n",
    "                                                  StructField(\"t_city_average_temperature\", DoubleType(), False),\n",
    "                                                  StructField(\"t_city_average_temperature_uncertainty\", DoubleType(), False),\n",
    "                                                  StructField(\"t_city_city\", StringType(), False),\n",
    "                                                  StructField(\"t_city_country\", StringType(), False),\n",
    "                                                  StructField(\"t_city_latitude\", StringType(), False),\n",
    "                                                  StructField(\"t_city_longitude\", StringType(), False)\n",
    "                                      ])\n",
    "    \n",
    "    return spark\\\n",
    "            .read\\\n",
    "            .format('com.databricks.spark.csv')\\\n",
    "            .option('sep',',')\\\n",
    "            .option('header', 'true')\\\n",
    "            .option(\"encoding\", \"utf-8\")\\\n",
    "            .schema(global_land_temp_by_city_schema)\\\n",
    "            .load(global_land_temperatures_by_city_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cities_demographics(spark):\n",
    "    us_cities_demog_schema = StructType([\\\n",
    "                                        StructField(\"cit_demog_city\", StringType(), False),\n",
    "                                        StructField(\"cit_demog_state\", StringType(), False),\n",
    "                                        StructField(\"cit_demog_median_age\", DoubleType(), False),\n",
    "                                        StructField(\"cit_demog_male_population\", IntegerType(), False),\n",
    "                                        StructField(\"cit_demog_female_population\", IntegerType(), False),\n",
    "                                        StructField(\"cit_demog_total_polulation\", IntegerType(), False),\n",
    "                                        StructField(\"cit_demog_number_veterans\", IntegerType(), False),\n",
    "                                        StructField(\"cit_demog_foreign_born\", IntegerType(), False),\n",
    "                                        StructField(\"cit_demog_average_household_size\", DoubleType(), False),\n",
    "                                        StructField(\"cit_demog_state_code\", StringType(), False),\n",
    "                                        StructField(\"cit_demog_race\", StringType(), False),\n",
    "                                        StructField(\"cit_demog_quant\", IntegerType(), False)\n",
    "                                        ])\n",
    "    \n",
    "    \n",
    "    return spark\\\n",
    "            .read\\\n",
    "            .format('com.databricks.spark.csv')\\\n",
    "            .option('sep',';')\\\n",
    "            .option('header', 'true')\\\n",
    "            .option(\"encoding\", \"utf-8\")\\\n",
    "            .schema(us_cities_demog_schema)\\\n",
    "            .load(us_cities_demographics_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_airport_codes(spark):\n",
    "    airport_codes_schema = StructType([\\\n",
    "                                       StructField(\"airp_ident\", StringType(), False),\n",
    "                                       StructField(\"airp_type\", StringType(), False),\n",
    "                                       StructField(\"airp_name\", StringType(), False),\n",
    "                                       StructField(\"airp_elevation_ft\", IntegerType(), False),\n",
    "                                       StructField(\"airp_continent\", StringType(), False),\n",
    "                                       StructField(\"airp_iso_country\", StringType(), False),\n",
    "                                       StructField(\"airp_iso_region\", StringType(), False),\n",
    "                                       StructField(\"airp_municipality\", StringType(), False),\n",
    "                                       StructField(\"airp_gps_code\", StringType(), False),\n",
    "                                       StructField(\"airp_iata_code\", StringType(), False),\n",
    "                                       StructField(\"airp_local_code\", StringType(), False),\n",
    "                                       StructField(\"airp_coordinates\", StringType(), False)\n",
    "                                      ])\n",
    "    \n",
    "    return spark\\\n",
    "            .read\\\n",
    "            .format('com.databricks.spark.csv')\\\n",
    "            .option('sep',',')\\\n",
    "            .option('header', 'true')\\\n",
    "            .option(\"encoding\", \"utf-8\")\\\n",
    "            .schema(airport_codes_schema)\\\n",
    "            .load(airport_codes_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_country(spark):\n",
    "    country_schema = StructType([\\\n",
    "                                  StructField(\"country_code\", IntegerType(), False),\n",
    "                                  StructField(\"country_name\", StringType(), False)\n",
    "                                 ])\n",
    "    \n",
    "    return spark\\\n",
    "            .read\\\n",
    "            .format('com.databricks.spark.csv')\\\n",
    "            .option('sep',';')\\\n",
    "            .option('header', 'true')\\\n",
    "            .option(\"encoding\", \"utf-8\")\\\n",
    "            .schema(country_schema)\\\n",
    "            .load(country_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_transport_vehicle(spark):\n",
    "    transport_vehicle_schema = StructType([\\\n",
    "                                           StructField(\"vehi_code\", IntegerType(), False),\n",
    "                                           StructField(\"vehi_name\", StringType(), False)\n",
    "                                          ])\n",
    "    \n",
    "    return spark\\\n",
    "            .read\\\n",
    "            .format('com.databricks.spark.csv')\\\n",
    "            .option('sep',';')\\\n",
    "            .option('header', 'true')\\\n",
    "            .option(\"encoding\", \"utf-8\")\\\n",
    "            .schema(transport_vehicle_schema)\\\n",
    "            .load(transport_vehicle_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_state_usa(spark):\n",
    "    state_usa_schema = StructType([\\\n",
    "                                   StructField(\"state_usa_code\", StringType(), False),\n",
    "                                   StructField(\"state_usa_name\", StringType(), False)\n",
    "                                  ])\n",
    "    \n",
    "    return spark\\\n",
    "            .read\\\n",
    "            .format('com.databricks.spark.csv')\\\n",
    "            .option('sep', ';')\\\n",
    "            .option('header', 'true')\\\n",
    "            .option('encoding', 'utf-8')\\\n",
    "            .schema(state_usa_schema)\\\n",
    "            .load(state_usa_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_motivation(spark):\n",
    "    motivation_schema = StructType([\\\n",
    "                                    StructField(\"motiv_code\", IntegerType(), False),\n",
    "                                    StructField(\"motiv_name\", StringType(), False)\n",
    "                                   ])\n",
    "    \n",
    "    return spark\\\n",
    "            .read\\\n",
    "            .format('com.databricks.spark.csv')\\\n",
    "            .option('sep', ';')\\\n",
    "            .option('header', 'true')\\\n",
    "            .option('encoding', 'utf-8')\\\n",
    "            .schema(motivation_schema)\\\n",
    "            .load(motivation_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_immigration(spark):\n",
    "    immigration_schema = StructType([\\\n",
    "                                   StructField(\"immig_passender_id\", IntegerType(), False),\n",
    "                                   StructField(\"immig_cicid\", DoubleType(), False),\n",
    "                                   StructField(\"immig_i94yr\", DoubleType(), False),\n",
    "                                   StructField(\"immig_i94mon\", DoubleType(), False),\n",
    "                                   StructField(\"immig_i94cit\", DoubleType(), False),\n",
    "                                   StructField(\"immig_i94res\", DoubleType(), False),\n",
    "                                   StructField(\"immig_i94port\", StringType(), False),\n",
    "                                   StructField(\"immig_arrdate\", DoubleType(), False),\n",
    "                                   StructField(\"immig_i94mode\", DoubleType(), False),\n",
    "                                   StructField(\"immig_i94addr\", StringType(), False),\n",
    "                                   StructField(\"immig_depdate\", DoubleType(), False),\n",
    "                                   StructField(\"immig_i94bir\", DoubleType(), False),\n",
    "                                   StructField(\"immig_i94visa\", DoubleType(), False),\n",
    "                                   StructField(\"immig_count\", DoubleType(), False),\n",
    "                                   StructField(\"immig_dtadfile\", StringType(), False),\n",
    "                                   StructField(\"immig_visapost\", StringType(), False),\n",
    "                                   StructField(\"immig_occup\", StringType(), False),\n",
    "                                   StructField(\"immig_entdepa\", StringType(), False),\n",
    "                                   StructField(\"immig_entdepd\", StringType(), False),\n",
    "                                   StructField(\"immig_entdepu\", StringType(), False),\n",
    "                                   StructField(\"immig_matflag\", StringType(), False),\n",
    "                                   StructField(\"immig_biryear\", DoubleType(), False),\n",
    "                                   StructField(\"immig_dtaddto\", StringType(), False),\n",
    "                                   StructField(\"immig_gender\", StringType(), False),\n",
    "                                   StructField(\"immig_insnum\", StringType(), False),\n",
    "                                   StructField(\"immig_airline\", StringType(), False),\n",
    "                                   StructField(\"immig_admnum\", DoubleType(), False),\n",
    "                                   StructField(\"immig_fltno\", StringType(), False),\n",
    "                                   StructField(\"immig_visatype\", StringType(), False)\n",
    "                                  ])\n",
    "    \n",
    "    return spark\\\n",
    "            .read\\\n",
    "            .format('com.databricks.spark.csv')\\\n",
    "            .option('sep', ',')\\\n",
    "            .option('header', 'true')\\\n",
    "            .option('encoding', 'utf-8')\\\n",
    "            .schema(immigration_schema)\\\n",
    "            .load(immigration_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_port(spark):\n",
    "    port_schema = StructType([\\\n",
    "                               StructField(\"port_code\", StringType(), False),\n",
    "                               StructField(\"port_name\", StringType(), False)\n",
    "                             ])\n",
    "    \n",
    "    df_port = spark\\\n",
    "            .read\\\n",
    "            .format('com.databricks.spark.csv')\\\n",
    "            .option('sep', ';')\\\n",
    "            .option('header', 'false')\\\n",
    "            .option('encoding', 'utf-8')\\\n",
    "            .schema(port_schema)\\\n",
    "            .load(port_path)\n",
    "\n",
    "    return df_port\\\n",
    "            .withColumn('column_drop', F.split(df_port['port_name'], ','))\\\n",
    "            .withColumn('port_portal', trim(F.col('column_drop')[0]))\\\n",
    "            .withColumn('port_country_acronym', trim(F.col('column_drop')[1]))\\\n",
    "            .drop('column_drop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def big_table(spark):\n",
    "    \n",
    "    df_temp_glob = load_temp_glob(spark).distinct()\n",
    "    \n",
    "    df_temp_state = load_temp_state(spark).select(\"t_state_state\", \"t_state_country\").distinct()\n",
    "    \n",
    "    df_temp_major_city = load_temp_major_city(spark).limit(1000)\n",
    "    \n",
    "    df_temp_country = load_temp_by_country(spark).limit(1000)\n",
    "    \n",
    "    df_temp_city = load_temp_by_city(spark).select(\"t_city_country\", \"t_city_city\").distinct()\n",
    "    \n",
    "    df_cities_demog = load_cities_demographics(spark).select(\"cit_demog_city\").distinct()\n",
    "    \n",
    "    df_airport_codes = load_airport_codes(spark).limit(1000)\n",
    "    \n",
    "    df_country = load_country(spark).select(\"country_name\", \"country_code\").distinct()\n",
    "    \n",
    "    df_transport_vehicle = load_transport_vehicle(spark).limit(1000)\n",
    "    \n",
    "    df_state_usa = load_state_usa(spark).distinct()\n",
    "    \n",
    "    df_motivation = load_motivation(spark)\n",
    "\n",
    "    df_immigration = load_immigration(spark)\n",
    "    \n",
    "    df_port = load_port(spark)\n",
    "    \n",
    "    df_join_state_temp_glob = df_state_usa\\\n",
    "    .join(df_temp_state, upper(df_state_usa.state_usa_name) == upper(df_temp_state.t_state_state))\n",
    "    \n",
    "    df_join = df_join_state_temp_glob\\\n",
    "    .join(df_temp_city, upper(df_join_state_temp_glob.t_state_country) == upper(df_temp_city.t_city_country))\\\n",
    "    .join(df_cities_demog, upper(df_temp_city.t_city_city) == upper(df_cities_demog.cit_demog_city))\\\n",
    "    .join(df_airport_codes, upper(df_airport_codes.airp_municipality) == upper(df_cities_demog.cit_demog_city))\\\n",
    "    .join(df_country, upper(df_country.country_name) == upper(df_temp_state.t_state_country))\\\n",
    "    .join(df_immigration, upper(df_immigration.immig_i94addr) == upper(df_join_state_temp_glob.state_usa_code))\\\n",
    "    .join(df_transport_vehicle, df_immigration.immig_i94mode == df_transport_vehicle.vehi_code)\\\n",
    "    .join(df_motivation, df_motivation.motiv_code == df_immigration.immig_i94visa)\n",
    "    \n",
    "    return df_join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    save_path = \"/home/alison/curso/ED-Udacity/capstone-pyspark/results/graph\"\n",
    "    \n",
    "    spark = create_spark_session()\n",
    "    \n",
    "    df_join = big_table(spark)\n",
    "    \n",
    "    df_join.write.format('com.databricks.spark.csv') \\\n",
    "     .mode('overwrite').option(\"header\", \"true\").save(save_path)\n",
    "    \n",
    "    return df_join\n",
    "    \n",
    "#     até aqui tudo esta funcionando, agora falta conectar as tabelas satelites "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start the application\n"
     ]
    }
   ],
   "source": [
    "result = main()\n",
    "\n",
    "result.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
