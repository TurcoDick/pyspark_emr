{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "from datetime import datetime\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, col, lit\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import year, month, dayofmonth, hour, weekofyear, date_format\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType, DateType\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spark_session():\n",
    "    \"\"\"\n",
    "    spark configuration.\n",
    "    \"\"\"\n",
    "    print(\"Start the application\")\n",
    "    spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:2.8.5\") \\\n",
    "        .getOrCreate()\n",
    "    return spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local paths in S3\n",
    "root_path = \"/home/alison/curso/ED-Udacity/capstone-athena/projeto-udacity/data/\"\n",
    "global_temperatures_path = root_path + \"temperatures/GlobalTemperatures.csv\"\n",
    "global_land_temperatures_by_state_path = root_path + \"temperatures/GlobalLandTemperaturesByState.csv\"\n",
    "global_land_temperatures_by_major_city_path = root_path + \"temperatures/GlobalLandTemperaturesByMajorCity.csv\"\n",
    "global_land_temperatures_by_country_path = root_path + \"temperatures/GlobalLandTemperaturesByCountry.csv\"\n",
    "global_land_temperatures_by_city_path = root_path + \"temperatures/GlobalLandTemperaturesByCity.csv\"\n",
    "us_cities_demographics_path = root_path + \"us_cities_demographics.csv\"\n",
    "airport_codes_csv_path = root_path + \"airport_codes_csv.csv\"\n",
    "country_path = root_path + \"country.csv\"\n",
    "transport_vehicle_path = root_path + \"transport_vehicle.csv\"\n",
    "state_usa_path = root_path + 'state_usa.csv'\n",
    "motivation_path = root_path + 'motivation.csv'\n",
    "immigration_path = root_path + 'immigration_data_sample.csv'\n",
    "port_path = root_path + 'port.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glob_temp_state(spark):\n",
    "    global_temperatures_by_state_schema = StructType([\\\n",
    "                                                  StructField(\"dt\", DateType(), False),\n",
    "                                                  StructField('average_temperature', DoubleType(), False),\n",
    "                                                  StructField('average_temperature_uncertainty', DoubleType(), False),\n",
    "                                                  StructField('state', StringType(), False),\n",
    "                                                  StructField('country', StringType(), False)\n",
    "                                          ]) \n",
    "    \n",
    "    return spark\\\n",
    "    .read\\\n",
    "    .format('com.databricks.spark.csv')\\\n",
    "    .option(\"sep\",\",\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .option(\"encoding\", \"UTF-8\")\\\n",
    "    .schema(global_temperatures_by_state_schema)\\\n",
    "    .load(global_land_temperatures_by_state_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glob_temp(spark):\n",
    "    global_temperatures_schema = StructType([ \\\n",
    "                                  StructField(\"dt\", DateType(), False),           \n",
    "                                  StructField(\"land_average_temperature\", DoubleType(), False),\n",
    "                                  StructField(\"land_average_temperature_uncertainty\", DoubleType(), False),\n",
    "                                  StructField(\"land_max_temperature\", DoubleType(), False), \n",
    "                                  StructField(\"land_max_temperature_uncertainty\", DoubleType(), False),\n",
    "                                  StructField(\"land_min_temperature\", DoubleType(), False), \n",
    "                                  StructField(\"land_min_temperature_uncertainty\", DoubleType(), False),\n",
    "                                  StructField(\"land_and_ocean_average_temperature\", DoubleType(), False),\n",
    "                                  StructField(\"land_and_ocean_average_temperature_uncertainty\", DoubleType(), False)           \n",
    "                            ])\n",
    "    return spark\\\n",
    "            .read\\\n",
    "            .format('com.databricks.spark.csv')\\\n",
    "            .option('sep',',')\\\n",
    "            .option(\"header\", \"true\")\\\n",
    "            .option(\"encoding\", \"UTF-8\")\\\n",
    "            .schema(global_temperatures_schema)\\\n",
    "            .load(global_temperatures_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_global_land_temp_major_city(spark):\n",
    "    global_temp_major_city_schema = StructType([\\\n",
    "                                                StructField(\"dt\", DateType(), False),\n",
    "                                                StructField(\"average_temperature\", DoubleType(), False),\n",
    "                                                StructField(\"average_temperature_uncertainty\", DoubleType(), False),\n",
    "                                                StructField(\"city\", StringType(), False),\n",
    "                                                StructField(\"country\", StringType(), False),\n",
    "                                                StructField(\"latitude\", StringType(), False),\n",
    "                                                StructField(\"longitude\", StringType(), False)\n",
    "                                ])\n",
    "    \n",
    "    return spark\\\n",
    "            .read\\\n",
    "            .format('com.databricks.spark.csv')\\\n",
    "            .option('sep',',')\\\n",
    "            .option('header', 'true')\\\n",
    "            .option(\"encoding\", \"UTF-8\")\\\n",
    "            .schema(global_temp_major_city_schema)\\\n",
    "            .load(global_land_temperatures_by_major_city_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_global_land_temp_by_country(spark):\n",
    "    global_land_temp_by_country_schema = StructType([\\\n",
    "                                                      StructField(\"dt\", DateType(), False),\n",
    "                                                      StructField(\"average_temperature\", DoubleType(), False),\n",
    "                                                      StructField(\"average_temperature_uncertainty\", DoubleType(), False),\n",
    "                                                      StructField(\"country\", StringType(), False)\n",
    "                                      ])\n",
    "    return spark\\\n",
    "            .read\\\n",
    "            .format('com.databricks.spark.csv')\\\n",
    "            .option('sep',',')\\\n",
    "            .option('header', 'true')\\\n",
    "            .option(\"encoding\", \"UTF-8\")\\\n",
    "            .schema(global_land_temp_by_country_schema)\\\n",
    "            .load(global_land_temperatures_by_country_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_global_land_temp_by_city(spark):\n",
    "    global_land_temp_by_city_schema = StructType([\\\n",
    "                                                  StructField(\"dt\", DateType(), False),\n",
    "                                                  StructField(\"average_temperature\", DoubleType(), False),\n",
    "                                                  StructField(\"average_temperature_uncertainty\", DoubleType(), False),\n",
    "                                                  StructField(\"city\", StringType(), False),\n",
    "                                                  StructField(\"country\", StringType(), False),\n",
    "                                                  StructField(\"latitude\", StringType(), False),\n",
    "                                                  StructField(\"longitude\", StringType(), False)\n",
    "                                      ])\n",
    "    \n",
    "    return spark\\\n",
    "            .read\\\n",
    "            .format('com.databricks.spark.csv')\\\n",
    "            .option('sep',',')\\\n",
    "            .option('header', 'true')\\\n",
    "            .option(\"encoding\", \"utf-8\")\\\n",
    "            .schema(global_land_temp_by_city_schema)\\\n",
    "            .load(global_land_temperatures_by_city_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_us_cities_demographics(spark):\n",
    "    us_cities_demog_schema = StructType([\\\n",
    "                                        StructField(\"city\", StringType(), False),\n",
    "                                        StructField(\"state\", StringType(), False),\n",
    "                                        StructField(\"median_age\", DoubleType(), False),\n",
    "                                        StructField(\"male_population\", IntegerType(), False),\n",
    "                                        StructField(\"female_population\", IntegerType(), False),\n",
    "                                        StructField(\"total_polulation\", IntegerType(), False),\n",
    "                                        StructField(\"number_veterans\", IntegerType(), False),\n",
    "                                        StructField(\"foreign_born\", IntegerType(), False),\n",
    "                                        StructField(\"average_household_size\", DoubleType(), False),\n",
    "                                        StructField(\"state_code\", StringType(), False),\n",
    "                                        StructField(\"race\", StringType(), False),\n",
    "                                        StructField(\"quant\", IntegerType(), False)\n",
    "                                        ])\n",
    "    \n",
    "    \n",
    "    return spark\\\n",
    "            .read\\\n",
    "            .format('com.databricks.spark.csv')\\\n",
    "            .option('sep',';')\\\n",
    "            .option('header', 'true')\\\n",
    "            .option(\"encoding\", \"utf-8\")\\\n",
    "            .schema(us_cities_demog_schema)\\\n",
    "            .load(us_cities_demographics_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_airport_codes(spark):\n",
    "    airport_codes_schema = StructType([\\\n",
    "                                       StructField(\"ident\", StringType(), False),\n",
    "                                       StructField(\"type\", StringType(), False),\n",
    "                                       StructField(\"name\", StringType(), False),\n",
    "                                       StructField(\"elevation_ft\", IntegerType(), False),\n",
    "                                       StructField(\"continent\", StringType(), False),\n",
    "                                       StructField(\"iso_country\", StringType(), False),\n",
    "                                       StructField(\"iso_region\", StringType(), False),\n",
    "                                       StructField(\"municipality\", StringType(), False),\n",
    "                                       StructField(\"gps_code\", StringType(), False),\n",
    "                                       StructField(\"iata_code\", StringType(), False),\n",
    "                                       StructField(\"local_code\", StringType(), False),\n",
    "                                       StructField(\"coordinates\", StringType(), False)\n",
    "                                      ])\n",
    "    \n",
    "    return spark\\\n",
    "            .read\\\n",
    "            .format('com.databricks.spark.csv')\\\n",
    "            .option('sep',',')\\\n",
    "            .option('header', 'true')\\\n",
    "            .option(\"encoding\", \"utf-8\")\\\n",
    "            .schema(airport_codes_schema)\\\n",
    "            .load(airport_codes_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_country(spark):\n",
    "    country_schema = StructType([\\\n",
    "                                  StructField(\"code\", IntegerType(), False),\n",
    "                                  StructField(\"name\", StringType(), False)\n",
    "                                 ])\n",
    "    \n",
    "    return spark\\\n",
    "            .read\\\n",
    "            .format('com.databricks.spark.csv')\\\n",
    "            .option('sep',';')\\\n",
    "            .option('header', 'true')\\\n",
    "            .option(\"encoding\", \"utf-8\")\\\n",
    "            .schema(country_schema)\\\n",
    "            .load(country_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_transport_vehicle(spark):\n",
    "    transport_vehicle_schema = StructType([\\\n",
    "                                           StructField(\"code\", IntegerType(), False),\n",
    "                                           StructField(\"name\", StringType(), False)\n",
    "                                          ])\n",
    "    \n",
    "    return spark\\\n",
    "            .read\\\n",
    "            .format('com.databricks.spark.csv')\\\n",
    "            .option('sep',';')\\\n",
    "            .option('header', 'true')\\\n",
    "            .option(\"encoding\", \"utf-8\")\\\n",
    "            .schema(transport_vehicle_schema)\\\n",
    "            .load(transport_vehicle_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_state_usa(spark):\n",
    "    state_usa_schema = StructType([\\\n",
    "                                   StructField(\"code\", StringType(), False),\n",
    "                                   StructField(\"name\", StringType(), False)\n",
    "                                  ])\n",
    "    \n",
    "    return spark\\\n",
    "            .read\\\n",
    "            .format('com.databricks.spark.csv')\\\n",
    "            .option('sep', ';')\\\n",
    "            .option('header', 'true')\\\n",
    "            .option('encoding', 'utf-8')\\\n",
    "            .schema(state_usa_schema)\\\n",
    "            .load(state_usa_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_motivation(spark):\n",
    "    motivation_schema = StructType([\\\n",
    "                                    StructField(\"code\", IntegerType(), False),\n",
    "                                    StructField(\"name\", StringType(), False)\n",
    "                                   ])\n",
    "    \n",
    "    return spark\\\n",
    "            .read\\\n",
    "            .format('com.databricks.spark.csv')\\\n",
    "            .option('sep', ';')\\\n",
    "            .option('header', 'true')\\\n",
    "            .option('encoding', 'utf-8')\\\n",
    "            .schema(motivation_schema)\\\n",
    "            .load(motivation_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_immigration(spark):\n",
    "    immigration_schema = StructType([\\\n",
    "                                   StructField(\"passender_id\", IntegerType(), False),\n",
    "                                   StructField(\"cicid\", DoubleType(), False),\n",
    "                                   StructField(\"i94yr\", DoubleType(), False),\n",
    "                                   StructField(\"i94mon\", DoubleType(), False),\n",
    "                                   StructField(\"i94cit\", DoubleType(), False),\n",
    "                                   StructField(\"i94res\", DoubleType(), False),\n",
    "                                   StructField(\"i94port\", StringType(), False),\n",
    "                                   StructField(\"arrdate\", DoubleType(), False),\n",
    "                                   StructField(\"i94mode\", DoubleType(), False),\n",
    "                                   StructField(\"i94addr\", StringType(), False),\n",
    "                                   StructField(\"depdate\", DoubleType(), False),\n",
    "                                   StructField(\"i94bir\", DoubleType(), False),\n",
    "                                   StructField(\"i94visa\", DoubleType(), False),\n",
    "                                   StructField(\"count\", DoubleType(), False),\n",
    "                                   StructField(\"dtadfile\", StringType(), False),\n",
    "                                   StructField(\"visapost\", StringType(), False),\n",
    "                                   StructField(\"occup\", StringType(), False),\n",
    "                                   StructField(\"entdepa\", StringType(), False),\n",
    "                                   StructField(\"entdepd\", StringType(), False),\n",
    "                                   StructField(\"entdepu\", StringType(), False),\n",
    "                                   StructField(\"matflag\", StringType(), False),\n",
    "                                   StructField(\"biryear\", DoubleType(), False),\n",
    "                                   StructField(\"dtaddto\", StringType(), False),\n",
    "                                   StructField(\"gender\", StringType(), False),\n",
    "                                   StructField(\"insnum\", StringType(), False),\n",
    "                                   StructField(\"airline\", StringType(), False),\n",
    "                                   StructField(\"admnum\", DoubleType(), False),\n",
    "                                   StructField(\"fltno\", StringType(), False),\n",
    "                                   StructField(\"visatype\", StringType(), False)\n",
    "                                  ])\n",
    "    \n",
    "    return spark\\\n",
    "            .read\\\n",
    "            .format('com.databricks.spark.csv')\\\n",
    "            .option('sep', ',')\\\n",
    "            .option('header', 'true')\\\n",
    "            .option('encoding', 'utf-8')\\\n",
    "            .schema(immigration_schema)\\\n",
    "            .load(immigration_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_port(spark):\n",
    "    port_schema = StructType([\\\n",
    "                               StructField(\"code\", StringType(), False),\n",
    "                               StructField(\"name\", StringType(), False)\n",
    "                             ])\n",
    "    \n",
    "    df_port = spark\\\n",
    "            .read\\\n",
    "            .format('com.databricks.spark.csv')\\\n",
    "            .option('sep', ';')\\\n",
    "            .option('header', 'false')\\\n",
    "            .option('encoding', 'utf-8')\\\n",
    "            .schema(port_schema)\\\n",
    "            .load(port_path)\n",
    "\n",
    "    return df_port\\\n",
    "            .withColumn('column_drop', F.split(df_port['name'], ','))\\\n",
    "            .withColumn('portal', trim(F.col('column_drop')[0]))\\\n",
    "            .withColumn('country_acronym', trim(F.col('column_drop')[1]))\\\n",
    "            .drop('column_drop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    spark = create_spark_session()\n",
    "    \n",
    "    df_glob_temp = load_glob_temp(spark).distinct()\n",
    "    \n",
    "    df_glob_temp_state = load_glob_temp_state(spark).select(\"state\", \"country\").distinct()\n",
    "    \n",
    "    df_glob_temp_major_city = load_global_land_temp_major_city(spark).limit(1000)\n",
    "    \n",
    "    df_glob_temp_country = load_global_land_temp_by_country(spark).limit(1000)\n",
    "    \n",
    "    df_glob_temp_city = load_global_land_temp_by_city(spark).select(\"country\", \"city\").distinct()\n",
    "    \n",
    "    df_us_cities_demog = load_us_cities_demographics(spark).select(\"city\").distinct()\n",
    "    \n",
    "    df_airport_codes = load_airport_codes(spark).limit(1000)\n",
    "    \n",
    "    df_country = load_country(spark).select(\"name\", \"code\").distinct()\n",
    "    \n",
    "    df_transport_vehicle = load_transport_vehicle(spark).limit(1000)\n",
    "    \n",
    "    df_state_usa = load_state_usa(spark).distinct()\n",
    "    \n",
    "    df_motivation = load_motivation(spark)\n",
    "\n",
    "    df_immigration = load_immigration(spark)\n",
    "    \n",
    "    df_port = load_port(spark)\n",
    "    \n",
    "    df_join_state_glob_temp = df_state_usa\\\n",
    "    .join(df_glob_temp_state, upper(df_state_usa.name) == upper(df_glob_temp_state.state))\n",
    "    \n",
    "    df_join = df_join_state_glob_temp\\\n",
    "    .join(df_glob_temp_city, upper(df_join_state_glob_temp.country) == upper(df_glob_temp_city.country))\\\n",
    "    .join(df_us_cities_demog, upper(df_glob_temp_city.city) == upper(df_us_cities_demog.city))\\\n",
    "    .join(df_airport_codes, upper(df_airport_codes.municipality) == upper(df_us_cities_demog.city))\\\n",
    "    .join(df_country, upper(df_country.name) == upper(df_glob_temp_state.country))\\\n",
    "    .join(df_immigration, upper(df_immigration.i94addr) == upper(df_join_state_glob_temp.code))\\\n",
    "    .limit(5)\n",
    "\n",
    "    \n",
    "    \n",
    "    print(df_join.limit(5).toPandas().head()) \n",
    "    \n",
    "#     até aqui tudo esta funcionando, agora falta conectar as tabelas satelites "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start the application\n",
      "   code   name  state        country        country              city  \\\n",
      "0    ID  IDAHO  Idaho  United States  United States  Huntington Beach   \n",
      "1    ID  IDAHO  Idaho  United States  United States      Indianapolis   \n",
      "2    ID  IDAHO  Idaho  United States  United States      Indianapolis   \n",
      "3    ID  IDAHO  Idaho  United States  United States           Detroit   \n",
      "4    ID  IDAHO  Idaho  United States  United States           Phoenix   \n",
      "\n",
      "               city ident      type                                name  \\\n",
      "0  Huntington Beach  02CA  heliport  Swepi Beta Platform Ellen Heliport   \n",
      "1      Indianapolis  0IN8    closed         Roto-Whirl/Vantage Heliport   \n",
      "2      Indianapolis  0IN7    closed         Roto-Whirl/Holiday Heliport   \n",
      "3           Detroit  0MI9  heliport        Henry Ford Hospital Heliport   \n",
      "4           Phoenix  0AZ7  heliport                   Sunstate Heliport   \n",
      "\n",
      "   elevation_ft continent iso_country iso_region      municipality gps_code  \\\n",
      "0           122        NA          US      US-CA  Huntington Beach     02CA   \n",
      "1           726        NA          US      US-IN      Indianapolis     None   \n",
      "2           875        NA          US      US-IN      Indianapolis     None   \n",
      "3           633        NA          US      US-MI           Detroit     0MI9   \n",
      "4          1180        NA          US      US-AZ           Phoenix     0AZ7   \n",
      "\n",
      "  iata_code local_code                             coordinates           name  \\\n",
      "0      None       02CA  -118.12899780273438, 33.58250045776367  UNITED STATES   \n",
      "1      None       None                   -86.118597, 39.837299  UNITED STATES   \n",
      "2      None       None                   -86.226097, 39.922501  UNITED STATES   \n",
      "3      None       0MI9   -83.08439636230469, 42.36750030517578  UNITED STATES   \n",
      "4      None       0AZ7  -111.96299743652344, 33.44369888305664  UNITED STATES   \n",
      "\n",
      "   code  passender_id      cicid   i94yr  i94mon  i94cit  i94res i94port  \\\n",
      "0     1       2388038  4865466.0  2016.0     4.0   123.0   123.0     SLC   \n",
      "1     1       2388038  4865466.0  2016.0     4.0   123.0   123.0     SLC   \n",
      "2     1       2388038  4865466.0  2016.0     4.0   123.0   123.0     SLC   \n",
      "3     1       2388038  4865466.0  2016.0     4.0   123.0   123.0     SLC   \n",
      "4     1       2388038  4865466.0  2016.0     4.0   123.0   123.0     SLC   \n",
      "\n",
      "   arrdate  i94mode i94addr  depdate  i94bir  i94visa  count  dtadfile  \\\n",
      "0  20570.0      1.0      ID  20581.0    28.0      2.0    1.0  20160426   \n",
      "1  20570.0      1.0      ID  20581.0    28.0      2.0    1.0  20160426   \n",
      "2  20570.0      1.0      ID  20581.0    28.0      2.0    1.0  20160426   \n",
      "3  20570.0      1.0      ID  20581.0    28.0      2.0    1.0  20160426   \n",
      "4  20570.0      1.0      ID  20581.0    28.0      2.0    1.0  20160426   \n",
      "\n",
      "  visapost occup entdepa entdepd entdepu matflag  biryear   dtaddto gender  \\\n",
      "0     None  None       G       O    None       M   1988.0  07242016      M   \n",
      "1     None  None       G       O    None       M   1988.0  07242016      M   \n",
      "2     None  None       G       O    None       M   1988.0  07242016      M   \n",
      "3     None  None       G       O    None       M   1988.0  07242016      M   \n",
      "4     None  None       G       O    None       M   1988.0  07242016      M   \n",
      "\n",
      "  insnum airline        admnum  fltno visatype  \n",
      "0   None      DL  5.929245e+10  00057       WT  \n",
      "1   None      DL  5.929245e+10  00057       WT  \n",
      "2   None      DL  5.929245e+10  00057       WT  \n",
      "3   None      DL  5.929245e+10  00057       WT  \n",
      "4   None      DL  5.929245e+10  00057       WT  \n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = create_spark_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_immigration = load_immigration(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_immigration.limit(10).toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_port = load_port(spark)\n",
    "df_port.limit(10).toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_country(spark).select(\"name\", \"code\").distinct().toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_global_land_temp_major_city(spark).distinct().toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_global_land_temp_by_city(spark).distinct().limit(5).toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_us_cities_demographics(spark).distinct().limit(5).toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_state_usa = load_state_usa(spark).distinct()\n",
    "\n",
    "df_immigration\\\n",
    "    .join(df_state_usa, upper(df_immigration.i94addr) == upper(df_state_usa.code))\\\n",
    "    .limit(5).toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp_state = load_glob_temp_state(spark)\n",
    "\n",
    "df_temp_state.join(df_state_usa, upper(df_temp_state.state) == upper(df_state_usa.name))\\\n",
    "    .limit(5).toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
