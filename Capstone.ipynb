{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "from datetime import datetime\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, col, lit\n",
    "import pyspark.sql.functions as psf\n",
    "from pyspark.sql.functions import year, month, dayofmonth, hour, weekofyear, date_format\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType, DateType\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spark_session():\n",
    "    \"\"\"\n",
    "    spark configuration.\n",
    "    \"\"\"\n",
    "    print(\"Start the application\")\n",
    "    spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:2.8.5\") \\\n",
    "        .getOrCreate()\n",
    "    return spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local paths in S3\n",
    "root_path = \"/home/alison/curso/ED-Udacity/capstone-athena/projeto-udacity/data/\"\n",
    "global_temperatures_path = root_path + \"temperatures/GlobalTemperatures.csv\"\n",
    "global_land_temperatures_by_state_path = root_path + \"temperatures/GlobalLandTemperaturesByState.csv\"\n",
    "global_land_temperatures_by_major_city_path = root_path + \"temperatures/GlobalLandTemperaturesByMajorCity.csv\"\n",
    "global_land_temperatures_by_country_path = root_path + \"temperatures/GlobalLandTemperaturesByCountry.csv\"\n",
    "global_land_temperatures_by_city_path = root_path + \"temperatures/GlobalLandTemperaturesByCity.csv\"\n",
    "us_cities_demographics_path = root_path + \"us_cities_demographics.csv\"\n",
    "airport_codes_csv_path = root_path + \"airport_codes_csv.csv\"\n",
    "country_path = root_path + \"country.csv\"\n",
    "transport_vehicle_path = root_path + \"transport_vehicle.csv\"\n",
    "state_usa_path = root_path + 'state_usa.csv'\n",
    "motivation_path = root_path + 'motivation.csv'\n",
    "immigration_path = root_path + 'immigration_data_sample.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glob_temp_state(spark):\n",
    "    global_temperatures_by_state_schema = StructType([\\\n",
    "                                                  StructField(\"dt\", DateType(), False),\n",
    "                                                  StructField('average_temperature', DoubleType(), False),\n",
    "                                                  StructField('average_temperature_uncertainty', DoubleType(), False),\n",
    "                                                  StructField('state', StringType(), False),\n",
    "                                                  StructField('country', StringType(), False)\n",
    "                                          ]) \n",
    "    \n",
    "    return spark\\\n",
    "    .read\\\n",
    "    .format('com.databricks.spark.csv')\\\n",
    "    .option(\"sep\",\",\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .option(\"encoding\", \"UTF-8\")\\\n",
    "    .schema(global_temperatures_by_state_schema)\\\n",
    "    .load(global_land_temperatures_by_state_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glob_temp(spark):\n",
    "    global_temperatures_schema = StructType([ \\\n",
    "                                  StructField(\"dt\", DateType(), False),           \n",
    "                                  StructField(\"land_average_temperature\", DoubleType(), False),\n",
    "                                  StructField(\"land_average_temperature_uncertainty\", DoubleType(), False),\n",
    "                                  StructField(\"land_max_temperature\", DoubleType(), False), \n",
    "                                  StructField(\"land_max_temperature_uncertainty\", DoubleType(), False),\n",
    "                                  StructField(\"land_min_temperature\", DoubleType(), False), \n",
    "                                  StructField(\"land_min_temperature_uncertainty\", DoubleType(), False),\n",
    "                                  StructField(\"land_and_ocean_average_temperature\", DoubleType(), False),\n",
    "                                  StructField(\"land_and_ocean_average_temperature_uncertainty\", DoubleType(), False)           \n",
    "                            ])\n",
    "    return spark\\\n",
    "            .read\\\n",
    "            .format('com.databricks.spark.csv')\\\n",
    "            .option('sep',',')\\\n",
    "            .option(\"header\", \"true\")\\\n",
    "            .option(\"encoding\", \"UTF-8\")\\\n",
    "            .schema(global_temperatures_schema)\\\n",
    "            .load(global_temperatures_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_global_land_temp_major_city(spark):\n",
    "    global_temp_major_city_schema = StructType([\\\n",
    "                                                StructField(\"dt\", DateType(), False),\n",
    "                                                StructField(\"average_temperature\", DoubleType(), False),\n",
    "                                                StructField(\"average_temperature_uncertainty\", DoubleType(), False),\n",
    "                                                StructField(\"city\", StringType(), False),\n",
    "                                                StructField(\"country\", StringType(), False),\n",
    "                                                StructField(\"latitude\", StringType(), False),\n",
    "                                                StructField(\"longitude\", StringType(), False)\n",
    "                                ])\n",
    "    \n",
    "    return spark\\\n",
    "            .read\\\n",
    "            .format('com.databricks.spark.csv')\\\n",
    "            .option('sep',',')\\\n",
    "            .option('header', 'true')\\\n",
    "            .option(\"encoding\", \"UTF-8\")\\\n",
    "            .schema(global_temp_major_city_schema)\\\n",
    "            .load(global_land_temperatures_by_major_city_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_global_land_temp_by_country(spark):\n",
    "    global_land_temp_by_country_schema = StructType([\\\n",
    "                                                      StructField(\"dt\", DateType(), False),\n",
    "                                                      StructField(\"average_temperature\", DoubleType(), False),\n",
    "                                                      StructField(\"average_temperature_uncertainty\", DoubleType(), False),\n",
    "                                                      StructField(\"country\", StringType(), False)\n",
    "                                      ])\n",
    "    return spark\\\n",
    "            .read\\\n",
    "            .format('com.databricks.spark.csv')\\\n",
    "            .option('sep',',')\\\n",
    "            .option('header', 'true')\\\n",
    "            .option(\"encoding\", \"UTF-8\")\\\n",
    "            .schema(global_land_temp_by_country_schema)\\\n",
    "            .load(global_land_temperatures_by_country_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_global_land_temp_by_city(spark):\n",
    "    global_land_temp_by_city_schema = StructType([\\\n",
    "                                                  StructField(\"dt\", DateType(), False),\n",
    "                                                  StructField(\"average_temperature\", DoubleType(), False),\n",
    "                                                  StructField(\"average_temperature_uncertainty\", DoubleType(), False),\n",
    "                                                  StructField(\"city\", StringType(), False),\n",
    "                                                  StructField(\"country\", StringType(), False),\n",
    "                                                  StructField(\"latitude\", StringType(), False),\n",
    "                                                  StructField(\"longitude\", StringType(), False)\n",
    "                                      ])\n",
    "    \n",
    "    return spark\\\n",
    "            .read\\\n",
    "            .format('com.databricks.spark.csv')\\\n",
    "            .option('sep',',')\\\n",
    "            .option('header', 'true')\\\n",
    "            .option(\"encoding\", \"utf-8\")\\\n",
    "            .schema(global_land_temp_by_city_schema)\\\n",
    "            .load(global_land_temperatures_by_city_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_us_cities_demographics(spark):\n",
    "    us_cities_demog_schema = StructType([\\\n",
    "                                        StructField(\"city\", StringType(), False),\n",
    "                                        StructField(\"state\", StringType(), False),\n",
    "                                        StructField(\"median_age\", DoubleType(), False),\n",
    "                                        StructField(\"male_population\", IntegerType(), False),\n",
    "                                        StructField(\"female_population\", IntegerType(), False),\n",
    "                                        StructField(\"total_polulation\", IntegerType(), False),\n",
    "                                        StructField(\"number_veterans\", IntegerType(), False),\n",
    "                                        StructField(\"foreign_born\", IntegerType(), False),\n",
    "                                        StructField(\"average_household_size\", DoubleType(), False),\n",
    "                                        StructField(\"state_code\", StringType(), False),\n",
    "                                        StructField(\"race\", StringType(), False),\n",
    "                                        StructField(\"quant\", IntegerType(), False)\n",
    "                                        ])\n",
    "    \n",
    "    \n",
    "    return spark\\\n",
    "            .read\\\n",
    "            .format('com.databricks.spark.csv')\\\n",
    "            .option('sep',';')\\\n",
    "            .option('header', 'true')\\\n",
    "            .option(\"encoding\", \"utf-8\")\\\n",
    "            .schema(us_cities_demog_schema)\\\n",
    "            .load(us_cities_demographics_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_airport_codes(spark):\n",
    "    airport_codes_schema = StructType([\\\n",
    "                                       StructField(\"ident\", StringType(), False),\n",
    "                                       StructField(\"type\", StringType(), False),\n",
    "                                       StructField(\"name\", StringType(), False),\n",
    "                                       StructField(\"elevation_ft\", IntegerType(), False),\n",
    "                                       StructField(\"continent\", StringType(), False),\n",
    "                                       StructField(\"iso_country\", StringType(), False),\n",
    "                                       StructField(\"iso_region\", StringType(), False),\n",
    "                                       StructField(\"municipality\", StringType(), False),\n",
    "                                       StructField(\"gps_code\", StringType(), False),\n",
    "                                       StructField(\"iata_code\", StringType(), False),\n",
    "                                       StructField(\"local_code\", StringType(), False),\n",
    "                                       StructField(\"coordinates\", StringType(), False)\n",
    "                                      ])\n",
    "    \n",
    "    return spark\\\n",
    "            .read\\\n",
    "            .format('com.databricks.spark.csv')\\\n",
    "            .option('sep',',')\\\n",
    "            .option('header', 'true')\\\n",
    "            .option(\"encoding\", \"utf-8\")\\\n",
    "            .schema(airport_codes_schema)\\\n",
    "            .load(airport_codes_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_country(spark):\n",
    "    country_schema = StructType([\\\n",
    "                                  StructField(\"code\", IntegerType(), False),\n",
    "                                  StructField(\"name\", StringType(), False)\n",
    "                                 ])\n",
    "    \n",
    "    return spark\\\n",
    "            .read\\\n",
    "            .format('com.databricks.spark.csv')\\\n",
    "            .option('sep',';')\\\n",
    "            .option('header', 'true')\\\n",
    "            .option(\"encoding\", \"utf-8\")\\\n",
    "            .schema(country_schema)\\\n",
    "            .load(country_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_transport_vehicle(spark):\n",
    "    transport_vehicle_schema = StructType([\\\n",
    "                                           StructField(\"code\", IntegerType(), False),\n",
    "                                           StructField(\"name\", StringType(), False)\n",
    "                                          ])\n",
    "    \n",
    "    return spark\\\n",
    "            .read\\\n",
    "            .format('com.databricks.spark.csv')\\\n",
    "            .option('sep',';')\\\n",
    "            .option('header', 'true')\\\n",
    "            .option(\"encoding\", \"utf-8\")\\\n",
    "            .schema(transport_vehicle_schema)\\\n",
    "            .load(transport_vehicle_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_state_usa(spark):\n",
    "    state_usa_schema = StructType([\\\n",
    "                                   StructField(\"code\", IntegerType(), False),\n",
    "                                   StructField(\"name\", StringType(), False)\n",
    "                                  ])\n",
    "    \n",
    "    return spark\\\n",
    "            .read\\\n",
    "            .format('com.databricks.spark.csv')\\\n",
    "            .option('sep', ';')\\\n",
    "            .option('header', 'true')\\\n",
    "            .option('encoding', 'utf-8')\\\n",
    "            .schema(state_usa_schema)\\\n",
    "            .load(state_usa_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_motivation(spark):\n",
    "    motivation_schema = StructType([\\\n",
    "                                    StructField(\"code\", IntegerType(), False),\n",
    "                                    StructField(\"name\", StringType(), False)\n",
    "                                   ])\n",
    "    \n",
    "    return spark\\\n",
    "            .read\\\n",
    "            .format('com.databricks.spark.csv')\\\n",
    "            .option('sep', ';')\\\n",
    "            .option('header', 'true')\\\n",
    "            .option('encoding', 'utf-8')\\\n",
    "            .schema(motivation_schema)\\\n",
    "            .load(motivation_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_immigration(spark):\n",
    "    immigration_schema = StructType([\\\n",
    "                                   StructField(\"passender_id\", IntegerType(), False),\n",
    "                                   StructField(\"cicid\", DoubleType(), False),\n",
    "                                   StructField(\"i94yr\", DoubleType(), False),\n",
    "                                   StructField(\"i94mon\", DoubleType(), False),\n",
    "                                   StructField(\"i94cit\", DoubleType(), False),\n",
    "                                   StructField(\"i94res\", DoubleType(), False),\n",
    "                                   StructField(\"i94port\", StringType(), False),\n",
    "                                   StructField(\"arrdate\", DoubleType(), False),\n",
    "                                   StructField(\"i94mode\", DoubleType(), False),\n",
    "                                   StructField(\"i94addr\", StringType(), False),\n",
    "                                   StructField(\"depdate\", DoubleType(), False),\n",
    "                                   StructField(\"i94bir\", DoubleType(), False),\n",
    "                                   StructField(\"i94visa\", DoubleType(), False),\n",
    "                                   StructField(\"count\", DoubleType(), False),\n",
    "                                   StructField(\"dtadfile\", StringType(), False),\n",
    "                                   StructField(\"visapost\", StringType(), False),\n",
    "                                   StructField(\"occup\", StringType(), False),\n",
    "                                   StructField(\"entdepa\", StringType(), False),\n",
    "                                   StructField(\"entdepd\", StringType(), False),\n",
    "                                   StructField(\"entdepu\", StringType(), False),\n",
    "                                   StructField(\"matflag\", StringType(), False),\n",
    "                                   StructField(\"biryear\", DoubleType(), False),\n",
    "                                   StructField(\"dtaddto\", StringType(), False),\n",
    "                                   StructField(\"gender\", StringType(), False),\n",
    "                                   StructField(\"insnum\", StringType(), False),\n",
    "                                   StructField(\"airline\", StringType(), False),\n",
    "                                   StructField(\"admnum\", DoubleType(), False),\n",
    "                                   StructField(\"fltno\", StringType(), False),\n",
    "                                   StructField(\"visatype\", StringType(), False)\n",
    "                                  ])\n",
    "    \n",
    "    return spark\\\n",
    "            .read\\\n",
    "            .format('com.databricks.spark.csv')\\\n",
    "            .option('sep', ',')\\\n",
    "            .option('header', 'true')\\\n",
    "            .option('encoding', 'utf-8')\\\n",
    "            .schema(immigration_schema)\\\n",
    "            .load(immigration_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    spark = create_spark_session()\n",
    "    \n",
    "    df_glob_temp = load_glob_temp(spark).distinct()\n",
    "#     df_glob_temp.show(truncate=False)\n",
    "#     df_glob_temp.printSchema()\n",
    "    \n",
    "    \n",
    "    df_glob_temp_state = load_glob_temp_state(spark).select(\"state\", \"country\").distinct()\n",
    "#     df_glob_temp_state.show()\n",
    "#     df_glob_temp_state.printSchema()\n",
    "    \n",
    "    df_glob_temp_major_city = load_global_land_temp_major_city(spark).limit(1000)\n",
    "#     df_glob_temp_major_city.show(truncate = False)\n",
    "#     df_glob_temp_major_city.printSchema()\n",
    "    \n",
    "    df_glob_temp_country = load_global_land_temp_by_country(spark).limit(1000)\n",
    "#     df_glob_temp_country.show(truncate = False)\n",
    "#     df_glob_temp_country.printSchema()\n",
    "    \n",
    "    df_glob_temp_city = load_global_land_temp_by_city(spark).select(\"country\", \"city\").distinct()\n",
    "#     df_glob_temp_city.show(truncate=False)\n",
    "#     df_glob_temp_city.printSchema()\n",
    "    \n",
    "    df_us_cities_demog = load_us_cities_demographics(spark).select(\"city\").distinct()\n",
    "#     df_us_cities_demog.show(truncate=False)\n",
    "#     df_us_cities_demog.printSchema()\n",
    "    \n",
    "    df_airport_codes = load_airport_codes(spark).limit(1000)\n",
    "#     df_airport_codes_csv.show(truncate=False)\n",
    "#     df_airport_codes_csv.printSchema()\n",
    "    \n",
    "    df_country = load_country(spark).select(\"name\", \"code\").distinct()\n",
    "#     df_country.show(truncate=False)\n",
    "#     df_country.printSchema()\n",
    "    \n",
    "    df_transport_vehicle = load_transport_vehicle(spark).limit(1000)\n",
    "#     df_transport_vehicle.show(truncate=False)\n",
    "#     df_transport_vehicle.printSchema()\n",
    "    \n",
    "    df_state_usa = load_state_usa(spark).select(\"name\").distinct()\n",
    "#     df_state_usa.show(truncate=False)\n",
    "#     df_state_usa.printSchema()\n",
    "    \n",
    "    df_motivation = load_motivation(spark)\n",
    "#     df_motivation.show(truncate=False)\n",
    "#     df_motivation.printSchema()\n",
    "\n",
    "    df_immigration = load_immigration(spark)\n",
    "    \n",
    "    \n",
    "    \n",
    "#     df_join_state_glob_temp = df_state_usa\\\n",
    "#     .join(df_glob_temp_state, upper(df_state_usa.name) == upper(df_glob_temp_state.state))\n",
    "    \n",
    "#     df_join = df_join_state_glob_temp\\\n",
    "#     .join(df_glob_temp_city, upper(df_join_state_glob_temp.country) == upper(df_glob_temp_city.country))\\\n",
    "#     .join(df_us_cities_demog, upper(df_glob_temp_city.city) == upper(df_us_cities_demog.city))\\\n",
    "#     .join(df_airport_codes, upper(df_airport_codes.municipality) == upper(df_us_cities_demog.city))\\\n",
    "#     .join(df_country, upper(df_country.name) == upper(df_glob_temp_state.country))\n",
    "    \n",
    "#     df_airport_codes.select(\"iata_code\",\"iso_country\", \"iso_region\",\"local_code\", \"coordinates\").show()\n",
    "#     df_country.show()\n",
    "#     df_country.filter(upper(df_country.name) == 'UNITED STATES').show()\n",
    "#     df_glob_temp_state.filter(upper(df_glob_temp_state.country) == 'UNITED STATES').show()\n",
    "    \n",
    "#     df_join = df_glob_temp_state.join(df_country, upper(df_country.name) == upper(df_glob_temp_state.country))\n",
    "    \n",
    "#     df_join.limit(10).show()\n",
    "    \n",
    "#     dfjoin = df_airport_codes.join(df_us_cities_demog, df_airport_codes.municipality == df_us_cities_demog.city)\n",
    "#     dfjoin.select(\"municipality\", \"city\").show(truncate=False)\n",
    "\n",
    "    df_immigration.select(\"i94cit\", \"i94res\", \"i94port\").show()\n",
    "    df_airport_codes.select(\"iata_code\",\"iso_country\", \"iso_region\",\"local_code\", \"coordinates\").show()\n",
    "    \n",
    "    df_immigraion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start the application\n",
      "+------+------+-------+\n",
      "|i94cit|i94res|i94port|\n",
      "+------+------+-------+\n",
      "| 209.0| 209.0|    HHW|\n",
      "| 582.0| 582.0|    MCA|\n",
      "| 148.0| 112.0|    OGG|\n",
      "| 297.0| 297.0|    LOS|\n",
      "| 111.0| 111.0|    CHM|\n",
      "| 577.0| 577.0|    ATL|\n",
      "| 245.0| 245.0|    SFR|\n",
      "| 113.0| 135.0|    NYC|\n",
      "| 131.0| 131.0|    CHI|\n",
      "| 116.0| 116.0|    LOS|\n",
      "| 438.0| 438.0|    LOS|\n",
      "| 209.0| 209.0|    PHI|\n",
      "| 148.0| 112.0|    FTL|\n",
      "| 260.0| 260.0|    LOS|\n",
      "| 148.0| 112.0|    BOS|\n",
      "| 245.0| 245.0|    SAI|\n",
      "| 512.0| 512.0|    NAS|\n",
      "| 689.0| 689.0|    FTL|\n",
      "| 746.0| 158.0|    SEA|\n",
      "| 260.0| 260.0|    FTL|\n",
      "+------+------+-------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+---------+-----------+----------+----------+--------------------+\n",
      "|iata_code|iso_country|iso_region|local_code|         coordinates|\n",
      "+---------+-----------+----------+----------+--------------------+\n",
      "|     null|         US|     US-PA|       00A|-74.9336013793945...|\n",
      "|     null|         US|     US-KS|      00AA|-101.473911, 38.7...|\n",
      "|     null|         US|     US-AK|      00AK|-151.695999146, 5...|\n",
      "|     null|         US|     US-AL|      00AL|-86.7703018188476...|\n",
      "|     null|         US|     US-AR|      null| -91.254898, 35.6087|\n",
      "|     null|         US|     US-OK|      00AS|-97.8180194, 34.9...|\n",
      "|     null|         US|     US-AZ|      00AZ|-112.165000915527...|\n",
      "|     null|         US|     US-CA|      00CA|-116.888000488, 3...|\n",
      "|     null|         US|     US-CA|      00CL|-121.763427, 39.4...|\n",
      "|     null|         US|     US-CA|      00CN|-116.4597417, 32....|\n",
      "|     null|         US|     US-CO|      null|-104.344002, 40.6...|\n",
      "|     null|         US|     US-FL|      00FA|-82.2190017700195...|\n",
      "|     null|         US|     US-FL|      00FD|-82.3453979492187...|\n",
      "|     null|         US|     US-FL|      00FL|-80.9692001342773...|\n",
      "|     null|         US|     US-GA|      00GA|-84.0682983398437...|\n",
      "|     null|         US|     US-GA|      00GE|-84.7339019775390...|\n",
      "|     null|         US|     US-HI|      00HI|-155.980233, 19.8...|\n",
      "|     null|         US|     US-ID|      00ID|-116.213996887207...|\n",
      "|     null|         US|     US-KS|      00IG|-101.395994, 39.7...|\n",
      "|     null|         US|     US-IN|      00II|-87.122802734375,...|\n",
      "+---------+-----------+----------+----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
